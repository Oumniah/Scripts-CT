{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd8a668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Oppened...\n"
     ]
    }
   ],
   "source": [
    "#group opened easy \n",
    "\n",
    "#no links appearing problems\n",
    "\n",
    "\n",
    "#log in, works! 2\n",
    "\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re \n",
    "\n",
    "#Send message New code after outage\n",
    "#Sends all links with description   ---> blocks when loading the page \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from tqdm import notebook\n",
    "import time\n",
    "#get description of the link\n",
    "from linkpreview import link_preview\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.remote.webdriver import WebDriver\n",
    "\n",
    "\n",
    "#import seaborn as sns    \n",
    "\n",
    "\n",
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "def attach_to_session(executor_url, session_id):\n",
    "    original_execute = WebDriver.execute\n",
    "    def new_command_execute(self, command, params=None):\n",
    "        if command == \"newSession\":\n",
    "            # Mock the response\n",
    "            return {'success': 0, 'value': None, 'sessionId': session_id}\n",
    "        else:\n",
    "            return original_execute(self, command, params)\n",
    "    # Patch the function before creating the driver object\n",
    "    WebDriver.execute = new_command_execute\n",
    "    driver = webdriver.Remote(command_executor=executor_url, desired_capabilities={})\n",
    "    driver.session_id = session_id\n",
    "    # Replace the patched function with original functions\n",
    "    WebDriver.execute = original_execute\n",
    "    return driver\n",
    "\n",
    "\n",
    "comments_list_all_posts = []\n",
    "raw_data_list = []\n",
    "links_list = []\n",
    "links_list1 = []  \n",
    "All_links_list = []\n",
    "New_All_links_list = []\n",
    "time_list = []\n",
    "\n",
    "\n",
    "\n",
    "url1 = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/url_FB.csv\")\n",
    "url1 = flatten_list(url1.values.tolist())[0]\n",
    "session_id = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/session_id_FB.csv\")\n",
    "session_id = flatten_list(session_id.values.tolist())[0]\n",
    "\n",
    "\n",
    "driver = attach_to_session(url1, session_id)\n",
    "sleep(3)\n",
    "driver.get('https://www.facebook.com/groups/480916455349909/search?q=Tramway&filters=eyJycF9jaHJvbm9fc29ydDowIjoie1wibmFtZVwiOlwiY2hyb25vc29ydFwiLFwiYXJnc1wiOlwiXCJ9In0%3D#')\n",
    "print(\"Group Oppened...\")\n",
    "time.sleep(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a108b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Tramway\n",
      "Tram\n",
      "Busway\n",
      "Bus\n",
      "باصواي\n",
      "ترامواي\n",
      "الطرام\n",
      "طرامواي\n",
      "طرام\n",
      "Transport\n",
      "Crawling done !\n",
      "filtering and flattering done !\n",
      "end of script\n"
     ]
    }
   ],
   "source": [
    "# optimized : search+recent replaced by links\n",
    "#optimized : search+recent replaced by links\n",
    "#Soup\n",
    "\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re \n",
    "#Send message New code after outage\n",
    "#Sends all links with description   ---> blocks when loading the page \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from tqdm import notebook\n",
    "import time\n",
    "#get description of the link\n",
    "from linkpreview import link_preview\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.remote.webdriver import WebDriver\n",
    "\n",
    "\n",
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "def attach_to_session(executor_url, session_id):\n",
    "    original_execute = WebDriver.execute\n",
    "    def new_command_execute(self, command, params=None):\n",
    "        if command == \"newSession\":\n",
    "            # Mock the response\n",
    "            return {'success': 0, 'value': None, 'sessionId': session_id}\n",
    "        else:\n",
    "            return original_execute(self, command, params)\n",
    "    # Patch the function before creating the driver object\n",
    "    WebDriver.execute = new_command_execute\n",
    "    driver = webdriver.Remote(command_executor=executor_url, desired_capabilities={})\n",
    "    driver.session_id = session_id\n",
    "    # Replace the patched function with original functions\n",
    "    WebDriver.execute = original_execute\n",
    "    return driver\n",
    "\n",
    "\n",
    "comments_list_all_posts = []\n",
    "raw_data_list = []\n",
    "links_list = []\n",
    "links_list1 = []  \n",
    "All_links_list = []\n",
    "New_All_links_list = []\n",
    "time_list = []\n",
    "\n",
    "\n",
    "url1 = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/url_FB.csv\")\n",
    "url1 = flatten_list(url1.values.tolist())[0]\n",
    "session_id = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/session_id_FB.csv\")\n",
    "session_id = flatten_list(session_id.values.tolist())[0]\n",
    "\n",
    "\n",
    "driver = attach_to_session(url1, session_id)\n",
    "sleep(5)\n",
    "\n",
    "print(\"Start\")\n",
    "\n",
    "driver.get('https://www.facebook.com/groups/480916455349909/search?q=Tramway&filters=eyJycF9jaHJvbm9fc29ydDowIjoie1wibmFtZVwiOlwiY2hyb25vc29ydFwiLFwiYXJnc1wiOlwiXCJ9In0%3D')\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "#mouse hover to show links\n",
    "element_to_hover_over = driver.find_element(By.CLASS_NAME,\"oajrlxb2.g5ia77u1.qu0x051f.esr5mh6w.e9989ue4.r7d6kgcz.rq0escxv.nhd2j8a9.nc684nl6.p7hjln8o.kvgmc6g5.cxmmr5t8.oygrvhab.hcukyx3x.jb3vyjys.rz4wbd8a.qt6c0cv9.a8nywdso.i1ao9s8h.esuyzwwr.f1sip0of.lzcic4wl.gmql0nx0.gpro0wi8.b1v8xokw\")\n",
    "\n",
    "hover = ActionChains(driver).move_to_element(element_to_hover_over)\n",
    "hover.perform()\n",
    "sleep(3)\n",
    "hover = ActionChains(driver).move_to_element(element_to_hover_over)\n",
    "hover.perform()\n",
    "\n",
    "sleep(3)\n",
    "All_links_to_post = driver.find_elements(By.XPATH,\"//a[@href]\")\n",
    "\n",
    "print('Tramway')\n",
    "for link in All_links_to_post:\n",
    "    #print(link.get_attribute(\"href\"))\n",
    "    links_list.append(link.get_attribute(\"href\"))\n",
    "\n",
    "All_links_list.append(links_list) #append to a list of lists\n",
    "#key words list\n",
    "words_list = ['Tram','Busway','Bus','باصواي','ترامواي','الطرام','طرامواي','طرام','Transport']\n",
    "#words_list = ['Tram','Busway','Bus']\n",
    "#words_list = ['Transport']\n",
    "\n",
    "#Search Key words loop\n",
    "for word in words_list :\n",
    "    \n",
    "    driver.get('https://www.facebook.com/groups/480916455349909/search?q='+word+'&filters=eyJycF9jaHJvbm9fc29ydDowIjoie1wibmFtZVwiOlwiY2hyb25vc29ydFwiLFwiYXJnc1wiOlwiXCJ9In0%3D')\n",
    "    sleep(5)\n",
    "    element_to_hover_over1 = driver.find_element(By.CLASS_NAME,\"oajrlxb2.g5ia77u1.qu0x051f.esr5mh6w.e9989ue4.r7d6kgcz.rq0escxv.nhd2j8a9.nc684nl6.p7hjln8o.kvgmc6g5.cxmmr5t8.oygrvhab.hcukyx3x.jb3vyjys.rz4wbd8a.qt6c0cv9.a8nywdso.i1ao9s8h.esuyzwwr.f1sip0of.lzcic4wl.gmql0nx0.gpro0wi8.b1v8xokw\")\n",
    "    \n",
    "    hover1 = ActionChains(driver).move_to_element(element_to_hover_over1)\n",
    "    hover1.perform()\n",
    "    sleep(3)\n",
    "    hover1 = ActionChains(driver).move_to_element(element_to_hover_over1)\n",
    "    hover1.perform()\n",
    "    \n",
    "    sleep(3)\n",
    "    All_links_to_post1 = driver.find_elements(By.XPATH,\"//a[@href]\")\n",
    "    print(word)\n",
    "    for link in All_links_to_post1:\n",
    "        #print(link.get_attribute(\"href\"))\n",
    "        links_list1.append(link.get_attribute(\"href\"))\n",
    "    All_links_list.append(links_list1)\n",
    "    \n",
    "print(\"Crawling done !\")\n",
    "\n",
    "\n",
    "#filter and delete comments\n",
    "\n",
    "def Filter(datalist):\n",
    "    # Search data based on regular expression in the list\n",
    "    return [val for val in datalist\n",
    "        if re.search(r'^https://www.facebook.com/groups/480916455349909/posts/', val)]\n",
    "\n",
    "def Split(datalist):\n",
    "    return [i.split('?', 1)[0] for i in datalist]\n",
    "\n",
    "def delete_comments(datalist):\n",
    "    return [val for val in datalist\n",
    "    if re.search(r'^((?!comment_id).)*$', val)]\n",
    "\n",
    "\n",
    "# Filter the list of the first keyword\n",
    "links_list = Filter(links_list)\n",
    "links_list = delete_comments(links_list)\n",
    "links_list = Split(links_list)\n",
    "\n",
    "# Filter the list of the rest of the keywords\n",
    "for l in All_links_list :\n",
    "    l = Filter(l)\n",
    "    l = delete_comments(l)\n",
    "    l = Split(l)\n",
    "    #if l not in saved_link_reste ://////////////\n",
    "    New_All_links_list.append(l)\n",
    "\n",
    "#turn a list of list to a simple list \n",
    "New_All_links_list = flatten_list(New_All_links_list)\n",
    "#set to drop duplicate\n",
    "New_All_links_list = list(set(New_All_links_list)) \n",
    "print(\"filtering and flattering done !\")\n",
    "\n",
    "##do it only on the first time \n",
    "#saved_links = New_All_links_list\n",
    "\n",
    "\n",
    "#get Only new posts\n",
    "\n",
    "#load old links from file\n",
    "saved_links_df = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/saved_links.csv\")\n",
    "saved_links = flatten_list(saved_links_df.values.tolist())\n",
    "\n",
    "\n",
    "def Diff(li1, li2):\n",
    "    return list(set(li1) - set(li2))\n",
    " \n",
    "N_All_links_list =  Diff(New_All_links_list,saved_links)\n",
    "\n",
    "#save the result into a list\n",
    "now = datetime.now()\n",
    "time_now = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "time_list = [time_now]\n",
    "saved_links.append(time_list)\n",
    "saved_links.append(N_All_links_list)\n",
    "N_All_links_list #this is the list to send via whatsapp \n",
    "\n",
    "\n",
    "#save the results to a file (old links)\n",
    "\n",
    "data = {'Links to posts' : flatten_list(saved_links)}\n",
    "saved_links_df = pd.DataFrame(data)\n",
    "saved_links_df.to_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/saved_links.csv\", index=False)\n",
    "saved_links_df.to_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/saved_links_backup.csv\", index=False)\n",
    "\n",
    "#save the results to a file ( to be sent)\n",
    "\n",
    "data = {'Links to posts' : flatten_list(N_All_links_list)}\n",
    "saved_links_df = pd.DataFrame(data)\n",
    "saved_links_df.to_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/to_be_sent.csv\", index=False)\n",
    "\n",
    "print(\"end of script\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#log in, works!\n",
    "\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "#from selenium.webdriver.support.ui import Selects\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re \n",
    "\n",
    "#Send message New code after outage\n",
    "#Sends all links with description   ---> blocks when loading the page \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "import urllib\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import tqdm \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.remote.webdriver import WebDriver\n",
    "\n",
    "#get description of the link\n",
    "from linkpreview import link_preview\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "url1 = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/url.csv\")\n",
    "url1 = flatten_list(url1.values.tolist())[0]\n",
    "session_id = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/session_id.csv\")\n",
    "session_id = flatten_list(session_id.values.tolist())[0]\n",
    "\n",
    "#url1 = \"http://localhost:63379\"\n",
    "#session_id = \"89d133fb5a44eff8503bc542d3094b56\"\n",
    "\n",
    "\n",
    "def attach_to_session(executor_url, session_id):\n",
    "    original_execute = WebDriver.execute\n",
    "    def new_command_execute(self, command, params=None):\n",
    "        if command == \"newSession\":\n",
    "            # Mock the response\n",
    "            return {'success': 0, 'value': None, 'sessionId': session_id}\n",
    "        else:\n",
    "            return original_execute(self, command, params)\n",
    "    # Patch the function before creating the driver object\n",
    "    WebDriver.execute = new_command_execute\n",
    "    driver = webdriver.Remote(command_executor=executor_url, desired_capabilities={})\n",
    "    driver.session_id = session_id\n",
    "    # Replace the patched function with original functions\n",
    "    WebDriver.execute = original_execute\n",
    "    return driver\n",
    "\n",
    "#flatteren list to delete duplicates\n",
    "\n",
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "#send message via wtsp functions\n",
    "def element_presence(by, xpath, time):\n",
    "    print(\"element presence\")\n",
    "    element_present = EC.presence_of_element_located((By.XPATH, xpath))\n",
    "    WebDriverWait(attach_to_session(url1, session_id), time).until(element_present)\n",
    "\n",
    "    \n",
    "\n",
    "def send_message(url,url1,session_id):\n",
    "    print(\"send message\")\n",
    "    \n",
    "    #driver_wtsp = webdriver.Remote(command_executor=url1,desired_capabilities={})\n",
    "    #driver_wtsp.close()   # this prevents the dummy browser\n",
    "    #driver_wtsp.session_id = session_id \n",
    "    #driver_wtsp.get(url)\n",
    "    \n",
    "    #new method\n",
    "    driver_wtsp = attach_to_session(url1, session_id)\n",
    "    driver_wtsp.get(url)\n",
    "    time.sleep(5) \n",
    "    \n",
    "    #element_presence(By.XPATH, '//*[@id=\"main\"]/footer/div[1]/div/div/div[2]/div[1]/div/div[2]', 40)\n",
    "    #element_presence(By.XPATH, '//*[@id=\"main\"]/footer/div[1]/div/span[2]/div/div[2]/div[1]/div/div[2]', 40)\n",
    "    msg_box = driver_wtsp.find_element(By.XPATH, '//*[@id=\"main\"]/footer/div[1]/div/span[2]/div/div[2]/div[1]/div/div[2]')\n",
    "    print(\"made it through element presence !\")\n",
    "    time.sleep(3)\n",
    "    msg_box.send_keys('\\n')    \n",
    "\n",
    "def prepare_msg(dataframe, link_col ,phone_col, url1,session_id):\n",
    "    print(\"prepare message\")\n",
    "    file = dataframe[[link_col, phone_col]]\n",
    "    base_msg = \"\"\"\n",
    "{}\n",
    "{}\n",
    "\n",
    "\n",
    "--Ce message est envoyé par un robot automatique--\n",
    "\"\"\"\n",
    "    base_url = 'https://web.whatsapp.com/send?phone={}&text={}'\n",
    "    for i,j in tqdm.tqdm(file.iterrows()):\n",
    "        phone_no = j[phone_col]\n",
    "        Link = j[link_col]\n",
    "        \n",
    "        for i in range(0,len(Link)):\n",
    "            msg = urllib.parse.quote(base_msg.format(link_preview(Link[i]).description,Link[i]))\n",
    "            url_msg = base_url.format(phone_no, msg)\n",
    "            send_message(url_msg, url1,session_id)\n",
    "            sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "to_be_sent_df = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/to_be_sent.csv\")\n",
    "\n",
    "now = datetime.now()\n",
    "time_now = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "if to_be_sent_df.empty == True :\n",
    "    print(time_now)\n",
    "    print(\"File is Empty\")\n",
    "    print(\"end of code\")\n",
    "\n",
    "else:\n",
    "    print(time_now)\n",
    "    print(\"File is not Empty\")\n",
    "    N_All_links_list = flatten_list(to_be_sent_df.values.tolist())\n",
    "\n",
    "    \n",
    "    #oumnia pro : +212666499291\n",
    "    #oumnia: +2126930524451\n",
    "    #soufiane : +212610205559\n",
    "    phones = ['+212693052451','+212610205559']\n",
    "    for i in range(0,len(phones)) :\n",
    "        data = {'Link' :[N_All_links_list], 'Phone' :phones[i]}\n",
    "        dummy2 = pd.DataFrame(data)\n",
    "        print(\"right before send\")\n",
    "        prepare_msg(dummy2, 'Link', 'Phone',url1,session_id)\n",
    "\n",
    "        \n",
    "N_All_links_list = []\n",
    "data = {'Links to posts' : flatten_list(N_All_links_list)}\n",
    "saved_links_df = pd.DataFrame(data)\n",
    "saved_links_df.to_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/to_be_sent.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4ff300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter and delete comments\n",
    "\n",
    "def Filter(datalist):\n",
    "    # Search data based on regular expression in the list\n",
    "    return [val for val in datalist\n",
    "        if re.search(r'^https://www.facebook.com/groups/480916455349909/posts/', val)]\n",
    "\n",
    "def delete_comments(datalist):\n",
    "    return [val for val in datalist\n",
    "    if re.search(r'^((?!comment_id).)*$', val)]\n",
    "\n",
    "\n",
    "# Filter the list of the first keyword\n",
    "links_list = Filter(links_list)\n",
    "links_list = delete_comments(links_list)\n",
    "\n",
    "# Filter the list of the rest of the keywords\n",
    "for l in All_links_list :\n",
    "    l = Filter(l)\n",
    "    l = delete_comments(l)\n",
    "    #if l not in saved_link_reste ://////////////\n",
    "    New_All_links_list.append(l)\n",
    "\n",
    "#turn a list of list to a simple list \n",
    "New_All_links_list = flatten_list(New_All_links_list)\n",
    "#set to drop duplicate\n",
    "New_All_links_list = list(set(New_All_links_list)) \n",
    "print(\"filtering and flattering done !\")\n",
    "\n",
    "##do it only on the first time \n",
    "#saved_links = New_All_links_list\n",
    "\n",
    "\n",
    "#get Only new posts\n",
    "\n",
    "#load old links from file\n",
    "saved_links_df = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/saved_links.csv\")\n",
    "saved_links = flatten_list(saved_links_df.values.tolist())\n",
    "\n",
    "\n",
    "def Diff(li1, li2):\n",
    "    return list(set(li1) - set(li2))\n",
    " \n",
    "N_All_links_list =  Diff(New_All_links_list,saved_links)\n",
    "\n",
    "#save the result into a list\n",
    "now = datetime.now()\n",
    "time_now = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "time_list = [time_now]\n",
    "saved_links.append(time_list)\n",
    "saved_links.append(N_All_links_list)\n",
    "N_All_links_list #this is the list to send via whatsapp \n",
    "\n",
    "\n",
    "#save the results to a file (old links)\n",
    "\n",
    "data = {'Links to posts' : flatten_list(saved_links)}\n",
    "saved_links_df = pd.DataFrame(data)\n",
    "saved_links_df.to_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/saved_links.csv\", index=False)\n",
    "saved_links_df.to_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/saved_links_backup.csv\", index=False)\n",
    "\n",
    "#save the results to a file ( to be sent)\n",
    "\n",
    "data = {'Links to posts' : flatten_list(N_All_links_list)}\n",
    "saved_links_df = pd.DataFrame(data)\n",
    "saved_links_df.to_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/to_be_sent.csv\", index=False)\n",
    "\n",
    "print(\"end of script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6650915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_7100/2427046245.py:107: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  All_links_to_post = driver.find_elements_by_xpath(\"//a[@href]\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tramway\n",
      "https://www.facebook.com/\n",
      "https://www.facebook.com/\n",
      "https://www.facebook.com/friends/\n",
      "https://www.facebook.com/watch/?ref=tab\n",
      "https://www.facebook.com/marketplace/?ref=app_tab\n",
      "https://www.facebook.com/gaming/?ref=games_tab\n",
      "https://www.facebook.com/bookmarks/\n",
      "https://www.facebook.com/notifications/\n",
      "https://www.facebook.com/me/\n",
      "https://www.facebook.com/notifications/\n",
      "https://www.facebook.com/Oumnia-hoummi-144115067795565/?modal=suggested_action&notif_id=1638510768955650&notif_t=page_user_activity&ref=notif\n",
      "https://www.facebook.com/Oumnia-hoummi-144115067795565/insights/?section=navPosts&notif_id=1636282982656130&notif_t=page_insights_weekly_digest&ref=notif\n",
      "https://www.facebook.com/Oumnia-hoummi-144115067795565/?modal=composer&notif_id=1637579112603731&notif_t=aymt_simplified_make_page_post&ref=notif\n",
      "https://www.facebook.com/Oumnia-hoummi-144115067795565/?modal=composer&notif_id=1637407611837785&notif_t=aymt_biz_growth_gain_fan_upsell_tip&ref=notif\n",
      "https://www.facebook.com/Oumnia-hoummi-144115067795565/?modal=composer&notif_id=1636806678727774&notif_t=aymt_simplified_make_page_post&ref=notif\n",
      "https://www.facebook.com/Oumnia-hoummi-144115067795565/?modal=composer&notif_id=1638015702048142&notif_t=aymt_biz_growth_gain_fan_upsell_tip&ref=notif\n",
      "https://www.facebook.com/Oumnia-hoummi-144115067795565/?modal=composer&notif_id=1638518962814484&notif_t=aymt_simplified_make_page_post&ref=notif\n",
      "https://www.facebook.com/groups/480916455349909/?multi_permalinks=4654341434674036&notif_id=1638799013593497&notif_t=group_highlights&ref=notif\n",
      "https://www.facebook.com/friends/requests/?profile_id=100005434121009&notif_id=1636808152906558&notif_t=friend&ref=notif\n",
      "https://www.facebook.com/groups/480916455349909/user/100003296748352/?__cft__[0]=AZXXMMfRoVbOFam10ldsI44yXAHiYlIO9M-zjXq0y3Kwi0f2mAaR5i5Brlh8w_kIzxSaMdJsBef-a_nR8gTOdkkKTDCll-tU9bxqtf_fLn0ic5a-ymUB2UnAFkc8zL3eIQMDIY2MFcaGmtJgPUlhd2Ey&__tn__=%3C%2CP-R\n",
      "https://www.facebook.com/groups/480916455349909/user/100003296748352/?__cft__[0]=AZXXMMfRoVbOFam10ldsI44yXAHiYlIO9M-zjXq0y3Kwi0f2mAaR5i5Brlh8w_kIzxSaMdJsBef-a_nR8gTOdkkKTDCll-tU9bxqtf_fLn0ic5a-ymUB2UnAFkc8zL3eIQMDIY2MFcaGmtJgPUlhd2Ey&__tn__=%3C%3C%2CP-R\n",
      "https://www.facebook.com/groups/480916455349909/user/100003296748352/?__cft__[0]=AZXXMMfRoVbOFam10ldsI44yXAHiYlIO9M-zjXq0y3Kwi0f2mAaR5i5Brlh8w_kIzxSaMdJsBef-a_nR8gTOdkkKTDCll-tU9bxqtf_fLn0ic5a-ymUB2UnAFkc8zL3eIQMDIY2MFcaGmtJgPUlhd2Ey&__tn__=-UC%2CP-R\n",
      "https://www.facebook.com/groups/480916455349909/posts/4656886861086160/?__cft__[0]=AZXXMMfRoVbOFam10ldsI44yXAHiYlIO9M-zjXq0y3Kwi0f2mAaR5i5Brlh8w_kIzxSaMdJsBef-a_nR8gTOdkkKTDCll-tU9bxqtf_fLn0ic5a-ymUB2UnAFkc8zL3eIQMDIY2MFcaGmtJgPUlhd2Ey&__tn__=%2CO%2CP-R\n",
      "https://www.facebook.com/photo/?fbid=4520643808055466&set=gm.4656886861086160&__cft__[0]=AZXXMMfRoVbOFam10ldsI44yXAHiYlIO9M-zjXq0y3Kwi0f2mAaR5i5Brlh8w_kIzxSaMdJsBef-a_nR8gTOdkkKTDCll-tU9bxqtf_fLn0ic5a-ymUB2UnAFkc8zL3eIQMDIY2MFcaGmtJgPUlhd2Ey&__tn__=EH-R\n",
      "https://www.facebook.com/groups/480916455349909/user/1611948315/?__cft__[0]=AZXMcgmV2Ib5iiRzoEH231gxeVReT7Cx2p_IsGCqr4KlUs0uompF3-dP7E96QK3km0movYgIZAZHAdNnj1KnGu0KVWC8kigHO99Fxc5yqtJQS-lWhtgTqN4Ig7QXfN-qm9KByr9WGyDJyT1JqFiR6Ltb&__tn__=%3C%2CP-R\n",
      "https://www.facebook.com/groups/480916455349909/user/1611948315/?__cft__[0]=AZXMcgmV2Ib5iiRzoEH231gxeVReT7Cx2p_IsGCqr4KlUs0uompF3-dP7E96QK3km0movYgIZAZHAdNnj1KnGu0KVWC8kigHO99Fxc5yqtJQS-lWhtgTqN4Ig7QXfN-qm9KByr9WGyDJyT1JqFiR6Ltb&__tn__=%3C%3C%2CP-R\n",
      "https://www.facebook.com/groups/480916455349909/user/1611948315/?__cft__[0]=AZXMcgmV2Ib5iiRzoEH231gxeVReT7Cx2p_IsGCqr4KlUs0uompF3-dP7E96QK3km0movYgIZAZHAdNnj1KnGu0KVWC8kigHO99Fxc5yqtJQS-lWhtgTqN4Ig7QXfN-qm9KByr9WGyDJyT1JqFiR6Ltb&__tn__=-UC%2CP-R\n",
      "https://www.facebook.com/groups/480916455349909/search?q=Tramway&filters=eyJycF9jaHJvbm9fc29ydDowIjoie1wibmFtZVwiOlwiY2hyb25vc29ydFwiLFwiYXJnc1wiOlwiXCJ9In0%3D#\n",
      "https://www.facebook.com/photo/?fbid=10224559093437444&set=gm.4655424264565753&__cft__[0]=AZXMcgmV2Ib5iiRzoEH231gxeVReT7Cx2p_IsGCqr4KlUs0uompF3-dP7E96QK3km0movYgIZAZHAdNnj1KnGu0KVWC8kigHO99Fxc5yqtJQS-lWhtgTqN4Ig7QXfN-qm9KByr9WGyDJyT1JqFiR6Ltb&__tn__=EH-R\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_7100/2427046245.py:129: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  All_links_to_post1 = driver.find_elements_by_xpath(\"//a[@href]\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling done !\n",
      "filtering and flattering done !\n",
      "end of script\n"
     ]
    }
   ],
   "source": [
    "#no links appearing problems\n",
    "#Soup\n",
    "\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re \n",
    "\n",
    "#Send message New code after outage\n",
    "#Sends all links with description   ---> blocks when loading the page \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from tqdm import notebook\n",
    "import time\n",
    "#get description of the link\n",
    "from linkpreview import link_preview\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.remote.webdriver import WebDriver\n",
    "\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "            \n",
    "\n",
    "#from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "#monExecutable = FirefoxBinary('C:/Users/ohoummi/Desktop/Python Scripts/Reclamations Script/geckodriver.exe')\n",
    "#driver = webdriver.Firefox(firefox_binary= 'firefox.exe')\n",
    "\n",
    "\n",
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "def attach_to_session(executor_url, session_id):\n",
    "    original_execute = WebDriver.execute\n",
    "    def new_command_execute(self, command, params=None):\n",
    "        if command == \"newSession\":\n",
    "            # Mock the response\n",
    "            return {'success': 0, 'value': None, 'sessionId': session_id}\n",
    "        else:\n",
    "            return original_execute(self, command, params)\n",
    "    # Patch the function before creating the driver object\n",
    "    WebDriver.execute = new_command_execute\n",
    "    driver = webdriver.Remote(command_executor=executor_url, desired_capabilities={})\n",
    "    driver.session_id = session_id\n",
    "    # Replace the patched function with original functions\n",
    "    WebDriver.execute = original_execute\n",
    "    return driver\n",
    "\n",
    "\n",
    "comments_list_all_posts = []\n",
    "raw_data_list = []\n",
    "links_list = []\n",
    "links_list1 = []  \n",
    "All_links_list = []\n",
    "New_All_links_list = []\n",
    "time_list = []\n",
    "\n",
    "\n",
    "\n",
    "url1 = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/url_FB.csv\")\n",
    "url1 = flatten_list(url1.values.tolist())[0]\n",
    "session_id = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/session_id_FB.csv\")\n",
    "session_id = flatten_list(session_id.values.tolist())[0]\n",
    "\n",
    "\n",
    "driver = attach_to_session(url1, session_id)\n",
    "sleep(5)\n",
    "\n",
    "\n",
    "driver.get('https://www.facebook.com/groups/480916455349909/search?q=Tramway&filters=eyJycF9jaHJvbm9fc29ydDowIjoie1wibmFtZVwiOlwiY2hyb25vc29ydFwiLFwiYXJnc1wiOlwiXCJ9In0%3D')\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "#mouse hover to show links\n",
    "element_to_hover_over = driver.find_element(By.CLASS_NAME,\"oajrlxb2.g5ia77u1.qu0x051f.esr5mh6w.e9989ue4.r7d6kgcz.rq0escxv.nhd2j8a9.nc684nl6.p7hjln8o.kvgmc6g5.cxmmr5t8.oygrvhab.hcukyx3x.jb3vyjys.rz4wbd8a.qt6c0cv9.a8nywdso.i1ao9s8h.esuyzwwr.f1sip0of.lzcic4wl.gmql0nx0.gpro0wi8.b1v8xokw\")\n",
    "sleep(5)\n",
    "hover = ActionChains(driver).move_to_element(element_to_hover_over)\n",
    "sleep(3)\n",
    "hover.perform()\n",
    "sleep(2)\n",
    "All_links_to_post = driver.find_elements_by_xpath(\"//a[@href]\")\n",
    "\n",
    "print('Tramway')\n",
    "for link in All_links_to_post:\n",
    "    print(link.get_attribute(\"href\"))\n",
    "    links_list.append(link.get_attribute(\"href\"))\n",
    "\n",
    "All_links_list.append(links_list) #append to a list of lists\n",
    "#key words list\n",
    "words_list = ['Tram','Busway','Bus','باصواي','ترامواي','Transport']\n",
    "#words_list = ['Tram','Busway','Bus']\n",
    "#words_list = ['Transport']\n",
    "\n",
    "#Search Key words loop\n",
    "for word in words_list :\n",
    "    \n",
    "    driver.get('https://www.facebook.com/groups/480916455349909/search?q='+word+'&filters=eyJycF9jaHJvbm9fc29ydDowIjoie1wibmFtZVwiOlwiY2hyb25vc29ydFwiLFwiYXJnc1wiOlwiXCJ9In0%3D')\n",
    "    sleep(5)\n",
    "    element_to_hover_over1 = driver.find_element(By.CLASS_NAME,\"oajrlxb2.g5ia77u1.qu0x051f.esr5mh6w.e9989ue4.r7d6kgcz.rq0escxv.nhd2j8a9.nc684nl6.p7hjln8o.kvgmc6g5.cxmmr5t8.oygrvhab.hcukyx3x.jb3vyjys.rz4wbd8a.qt6c0cv9.a8nywdso.i1ao9s8h.esuyzwwr.f1sip0of.lzcic4wl.gmql0nx0.gpro0wi8.b1v8xokw\")\n",
    "    hover1 = ActionChains(driver).move_to_element(element_to_hover_over1)\n",
    "    hover1.perform()\n",
    "    sleep(3)\n",
    "    All_links_to_post1 = driver.find_elements_by_xpath(\"//a[@href]\")\n",
    "    for link in All_links_to_post1:\n",
    "        #print(link.get_attribute(\"href\"))\n",
    "        links_list1.append(link.get_attribute(\"href\"))\n",
    "    All_links_list.append(links_list1)\n",
    "    \n",
    "print(\"Crawling done !\")\n",
    "\n",
    "\n",
    "#filter and delete comments\n",
    "\n",
    "def Filter(datalist):\n",
    "    # Search data based on regular expression in the list\n",
    "    return [val for val in datalist\n",
    "        if re.search(r'^https://www.facebook.com/groups/480916455349909/posts/', val)]\n",
    "\n",
    "def Split(datalist):\n",
    "    return [i.split('?', 1)[0] for i in datalist]\n",
    "\n",
    "def delete_comments(datalist):\n",
    "    return [val for val in datalist\n",
    "    if re.search(r'^((?!comment_id).)*$', val)]\n",
    "\n",
    "\n",
    "# Filter the list of the first keyword\n",
    "links_list = Filter(links_list)\n",
    "links_list = delete_comments(links_list)\n",
    "links_list = Split(links_list)\n",
    "\n",
    "# Filter the list of the rest of the keywords\n",
    "for l in All_links_list :\n",
    "    l = Filter(l)\n",
    "    l = delete_comments(l)\n",
    "    l = Split(l)\n",
    "    #if l not in saved_link_reste ://////////////\n",
    "    New_All_links_list.append(l)\n",
    "\n",
    "#turn a list of list to a simple list \n",
    "New_All_links_list = flatten_list(New_All_links_list)\n",
    "#set to drop duplicate\n",
    "New_All_links_list = list(set(New_All_links_list)) \n",
    "print(\"filtering and flattering done !\")\n",
    "\n",
    "##do it only on the first time \n",
    "#saved_links = New_All_links_list\n",
    "\n",
    "\n",
    "#get Only new posts\n",
    "\n",
    "#load old links from file\n",
    "saved_links_df = pd.read_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/saved_links.csv\")\n",
    "saved_links = flatten_list(saved_links_df.values.tolist())\n",
    "\n",
    "\n",
    "def Diff(li1, li2):\n",
    "    return list(set(li1) - set(li2))\n",
    " \n",
    "N_All_links_list =  Diff(New_All_links_list,saved_links)\n",
    "\n",
    "#save the result into a list\n",
    "now = datetime.now()\n",
    "time_now = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "time_list = [time_now]\n",
    "saved_links.append(time_list)\n",
    "saved_links.append(N_All_links_list)\n",
    "N_All_links_list #this is the list to send via whatsapp \n",
    "\n",
    "\n",
    "#save the results to a file (old links)\n",
    "\n",
    "data = {'Links to posts' : flatten_list(saved_links)}\n",
    "saved_links_df = pd.DataFrame(data)\n",
    "saved_links_df.to_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/saved_links.csv\", index=False)\n",
    "saved_links_df.to_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/saved_links_backup.csv\", index=False)\n",
    "\n",
    "#save the results to a file ( to be sent)\n",
    "\n",
    "data = {'Links to posts' : flatten_list(N_All_links_list)}\n",
    "saved_links_df = pd.DataFrame(data)\n",
    "saved_links_df.to_csv(\"C:/Users/Administrateur/Desktop/Scripts/ReclamationsScript/to_be_sent.csv\", index=False)\n",
    "\n",
    "print(\"end of script\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
